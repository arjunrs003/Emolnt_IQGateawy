# -*- coding: utf-8 -*-
"""Emolnt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YAYD1OoDN2_dfZcIgbN33wzTr5RVMJYL
"""

import pandas as pd
import string
from nltk.tokenize import word_tokenize
import re
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LinearRegression
from sklearn import svm
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import scipy


path = r"D:\Data Science Study material\IQGateway\Emolnt_IQGateawy\dataset\"
cols = ['id', 'text', 'label', 'intensity']
anger = pd.read_csv(path + 'train_anger.txt', header=None, sep='\t', names=cols, index_col=0)
fear = pd.read_csv(path + 'train_fear.txt', header=None, sep='\t', names=cols, index_col=0)
sad = pd.read_csv(path + 'train_sadness.txt', header=None, sep='\t', names=cols, index_col=0)
joy = pd.read_csv(path + 'train_joy.txt', header=None, sep='\t', names=cols, index_col=0)


express = [anger, fear, sad, joy]
df_train = pd.concat(express)
df_train.reset_index(inplace=True)



punctuations = string.punctuation
stopwords = stopwords.words("english")
total_stopwords = stopwords+list(punctuations)
total_stopwords.remove("not")

def contractions(s):
    s = re.sub(r"won't", "will not",s)
    s = re.sub(r"would't", "would not",s)
    s = re.sub(r"could't", "could not",s)
    s = re.sub(r"\'d", "would",s)
    s = re.sub(r"can\'t", "can not",s)
    s = re.sub(r"n\'t", "not", s)
    s= re.sub(r"\'re", "are", s)
    s = re.sub(r"\'s", "is", s)
    s = re.sub(r"\"ll", "will", s)
    s = re.sub(r"\'t", "not", s)
    s = re.sub(r"\'ve", "have", s)
    s = re.sub(r"\'m", "am", s)
    s = re.sub("([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)"," ",s)
    s = re.sub("[^A-Za-z ]"," ",s)
    return s

df_train['text']=df_train['text'].apply(lambda x:contractions(x))

lema = WordNetLemmatizer()

def clean_data(text):
    cleaned = []
    for headline in text:
        headlines = re.sub(r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"," ",headline)   #url
        headlines = re.sub("([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)"," ",headlines)       #email
        headlines = re.sub("[^A-Za-z ]"," ",headlines)
        headlines = headlines.lower()
        headlines = word_tokenize(headlines)
        print(headlines)
        headlines = [lema.lemmatize(word) for word in headlines if word not in total_stopwords]
        cleaned.append(" ".join(headlines))
    return cleaned

text = clean_data(df_train['text'])

df_train.text = pd.DataFrame(text)

label_encoder = LabelEncoder()

df_train['label']= label_encoder.fit_transform(df_train['label'])

x_df_train = df_train.drop('intensity',axis=1)

y_df_train = df_train['intensity']



vectorizer_tfidf = TfidfVectorizer(max_features=1000)
x_tfidf = vectorizer_tfidf.fit_transform(x_df_train['text'])
x_tfidf = pd.DataFrame.sparse.from_spmatrix(x_tfidf).join(x_df_train['label'])


x_tfidf.columns = x_tfidf.columns.astype(str)



#linear regression
tfidf_linear = LinearRegression().fit(x_tfidf, y_df_train)
#svm regressor
tfidf_svr = svm.SVR().fit(x_tfidf, y_df_train)

path = "/content/drive/MyDrive/"
cols = ['id', 'text', 'label', 'intensity']
dev_anger = pd.read_csv(path + 'dev_anger.txt', header=None, sep='\t', names=cols, index_col=0)
dev_fear = pd.read_csv(path + 'dev_fear.txt', header=None, sep='\t', names=cols, index_col=0)
dev_sad = pd.read_csv(path + 'dev_sadness.txt', header=None, sep='\t', names=cols, index_col=0)
dev_joy = pd.read_csv(path + 'dev_joy.txt', header=None, sep='\t', names=cols, index_col=0)
dev_anger_intensity = pd.read_csv(path + 'dev_anger_intensity.txt', header=None, sep='\t', names=cols, index_col=0)
dev_fear_intensity = pd.read_csv(path + 'dev_fear_intensity.txt', header=None, sep='\t', names=cols, index_col=0)
dev_sad_intensity = pd.read_csv(path + 'dev_sadness_intensity.txt', header=None, sep='\t', names=cols, index_col=0)
dev_joy_intensity = pd.read_csv(path + 'dev_joy_intensity.txt', header=None, sep='\t', names=cols, index_col=0)



express = [dev_anger, dev_fear, dev_sad, dev_joy,dev_anger_intensity, dev_fear_intensity, dev_sad_intensity, dev_joy_intensity]
dev_df = pd.concat(express)
dev_df.reset_index(inplace=True)


dev_df['text']=dev_df['text'].apply(lambda x:contractions(x))

text = clean_data(dev_df['text'])

dev_df.text = pd.DataFrame(text)

dev_df['label']= label_encoder.fit_transform(dev_df['label'])

x_dev_df = dev_df.drop('intensity',axis=1)

y_dev_df = dev_df['intensity']

y_dev_df=pd.to_numeric(y_dev_df, errors='coerce').fillna(0)

vectorizer_tfidf = TfidfVectorizer(max_features=1000)
x_dev_df_tfidf = vectorizer_tfidf.fit_transform(x_dev_df['text'])
x_dev_df_tfidf = pd.DataFrame.sparse.from_spmatrix(x_dev_df_tfidf).join(x_dev_df['label'])

x_dev_df_tfidf.columns = x_dev_df_tfidf.columns.astype(str)

def get_score(y_test, y_pred, name):
    print(name + '\n')
    print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
    print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
    print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))
    return mean_absolute_error(y_test, y_pred),mean_squared_error(y_test, y_pred),np.sqrt(mean_squared_error(y_test, y_pred))

tfidf_linear.predict(x_dev_df_tfidf)

predict = {'linear':tfidf_linear.predict(x_dev_df_tfidf),'svm':tfidf_svr.predict(x_dev_df_tfidf)}
for i in predict:
  get_score(y_dev_df,predict[i],i)

y_actual = y_dev_df
y_predicted = tfidf_svr.predict(x_dev_df_tfidf)

pd.DataFrame(data={"Actual Intensity" : y_actual, "Predicted Intensity" : y_predicted})

combined_df = pd.concat([df_train[['id', 'text', 'label', 'intensity']], dev_df]).reset_index()

combined_df['intensity']=pd.to_numeric(combined_df['intensity'], errors='coerce').fillna(0)

anger = combined_df.loc[combined_df['label']==0]
anger_vectorizer = TfidfVectorizer(max_features=1000)
x_anger = anger_vectorizer.fit_transform(anger['text'])
anger_model = svm.SVR().fit(x_anger, anger['intensity'])

#FEAR
fear = combined_df.loc[combined_df['label']==1]
fear_vectorizer = TfidfVectorizer(max_features=1000)
x_fear = fear_vectorizer.fit_transform(fear['text'])
fear_model = svm.SVR().fit(x_fear, fear['intensity'])

#SADNESS
sad = combined_df.loc[combined_df['label']==3]
sad_vectorizer = TfidfVectorizer(max_features=1000)
x_sad = sad_vectorizer.fit_transform(sad['text'])
sad_model = svm.SVR().fit(x_sad, sad['intensity'])

#JOY
joy = combined_df.loc[combined_df['label']==2]
joy_vectorizer = TfidfVectorizer(max_features=1000)
x_joy = joy_vectorizer.fit_transform(joy['text'])
joy_model = svm.SVR().fit(x_joy, joy['intensity'])

cols = ["id", "text", "label", "intensity"]
anger_test = pd.read_csv(path + "test_anger.txt", header=None, sep="\t", names=cols, index_col=0)
fear_test = pd.read_csv(path + "test_fear.txt", header=None, sep="\t", names=cols, index_col=0)
sad_test = pd.read_csv(path + "test_sadness.txt", header=None, sep="\t", names=cols, index_col=0)
joy_test = pd.read_csv(path + "test_joy.txt", header=None, sep="\t", names=cols, index_col=0)
anger_test_intensity = pd.read_csv(path + "test_anger_intensity.txt", header=None, sep="\t", names=cols, index_col=0)
fear_test_intensity = pd.read_csv(path + "test_fear_intensity.txt", header=None, sep="\t", names=cols, index_col=0)
sad_test_intensity = pd.read_csv(path + "test_sadness_intensity.txt", header=None, sep="\t", names=cols, index_col=0)
joy_test_intensity = pd.read_csv(path + "test_joy_intensity.txt", header=None, sep="\t", names=cols, index_col=0)


w_intensity = [anger_test,fear_test,sad_test,joy_test,anger_test_intensity,fear_test_intensity,sad_test_intensity,joy_test_intensity]
for i in w_intensity:
  i['intensity']=pd.to_numeric(i['intensity'], errors='coerce').fillna(0)
  text = clean_data(i['text'])
  i['text']=i['text'].apply(lambda x:contractions(x))

express = [anger_test,anger_test_intensity]
df_test_anger = pd.concat(express)
df_test_anger.reset_index(inplace=True)


express = [fear_test,fear_test_intensity]
df_test_fear = pd.concat(express)
df_test_fear.reset_index(inplace=True)


express = [sad_test,sad_test_intensity]
df_test_sad = pd.concat(express)
df_test_sad.reset_index(inplace=True)


express = [joy_test,joy_test_intensity]
df_test_joy = pd.concat(express)
df_test_joy.reset_index(inplace=True)


# X_anger_test = df_test_anger.drop(['intensity'],axis=1)
# Y_anger_actual = df_test_anger['intensity']

#ANGER
X_anger_test = anger_vectorizer.transform(df_test_anger['text'])
Y_anger_actual = df_test_anger['intensity']
Y_anger_predicted = anger_model.predict(X_anger_test)

#FEAR
X_fear_test = fear_vectorizer.transform(df_test_fear['text'])
Y_fear_actual = df_test_fear['intensity']
Y_fear_predicted = fear_model.predict(X_fear_test)

#SADNESS
X_sad_test = sad_vectorizer.transform(df_test_sad['text'])
Y_sad_actual = df_test_sad['intensity']
Y_sad_predicted = sad_model.predict(X_sad_test)

#JOY
X_joy_test = joy_vectorizer.transform(df_test_joy['text'])
Y_joy_actual = df_test_joy['intensity']
Y_joy_predicted = joy_model.predict(X_joy_test)

df_test_anger['text'].shape

get_score(Y_anger_actual, Y_anger_predicted, "Result of Anger Model")
get_score(Y_fear_actual, Y_fear_predicted, "Result of Fear Model")
get_score(Y_sad_actual, Y_sad_predicted, "Result of Sadness Model")
get_score(Y_joy_actual, Y_joy_predicted, "Result of Joy Model")



def evaluate(pred,gold):
    gold_scores=[]
    pred_scores=[]
    gold_scores_range_05_1=[]
    pred_scores_range_05_1=[]
    for p in pred:
        pred_scores.append(p)
    for g in gold:
        gold_scores.append(g)
    for i in range(len(gold_scores)):
        if gold_scores[i] >= 0.5:
            gold_scores_range_05_1.append(gold_scores[i])
            pred_scores_range_05_1.append(pred_scores[i])

    if np.std(pred_scores)==0 or np.std(gold_scores)==0:
        return (0,0,0,0)

    pears_corr=scipy.stats.pearsonr(pred_scores,gold_scores)[0]
    pears_corr_range_05_1=scipy.stats.pearsonr(pred_scores_range_05_1,gold_scores_range_05_1)[0]

    return (pears_corr,pears_corr_range_05_1)

pear_results=[]
spear_results=[]
pear_results_range_05_1=[]
spear_results_range_05_1=[]

num_pairs = 4
argv = ["Anger_Actual", Y_anger_actual, "Anger_Predicted", Y_anger_predicted, "Fear_Actual", Y_fear_actual, "Fear_Predicted", Y_fear_predicted, "Sad_Actual", Y_sad_actual, "Sad_Predicted", Y_sad_predicted, "Joy_Actual", Y_joy_actual, "Joy_Predicted", Y_joy_predicted]

for i in range(0,len(argv),4):
    name_gold = argv[i]
    gold=argv[i+1]
    name_pred = argv[i+2]
    pred=argv[i+3]
    result=evaluate(pred,gold)
    print ("Pearson correlation between ", name_pred, " and ", name_gold, ":\t", str(result[0]))
    pear_results.append(result[0])
    print ("Pearson correlation for gold scores in range 0.5-1 between ",name_pred," and ",name_gold,":\t",str(result[1]))
    pear_results_range_05_1.append(result[1])

avg_pear=np.mean(pear_results)

avg_pear_range_05_1=np.mean(pear_results_range_05_1)

print ("Average Pearson correlation:\t",str(avg_pear))

print ("Average Pearson correlation for gold scores in range 0.5-1:\t", str(avg_pear_range_05_1))

